{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationSummaryMemory, ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import OpenAIFunctionsAgent\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "openai_api_key = \"\"\n",
    "\n",
    "llm=ChatOpenAI()  # Creting instance for OpenAi gpt-3.5-turbo model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating memory instance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory= ConversationBufferMemory()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating chain from LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=memory\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below message alos go as a prompt to OpenAI  and storing 'Prompt' in 'Prompt' varibale\n",
    "\n",
    "##### I am asking user details for upcoming upated app version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_message = SystemMessage(content=\"\"\" 'Act as a stubborn who need user details,Chatflow should follow a conversational format, where the bot responds to each user question by understanding the context and asking specific questions to move the conversation forward. The goal is to collect user details'\n",
    "\n",
    " \"Introduce you with first \"Hi I am Ninja AI Bot I need some details for the upcoming Update version for our App as you are using now.So Are you ready for the Update?\"\\n\n",
    "\n",
    "if user say yes, Ask user follow-up Quesition which is given below one by one :\\n\n",
    " name\n",
    " age\n",
    "mobile number\n",
    " Email-id'\\n\n",
    "                               \n",
    "Remember do not proceed forward if user does not share all three details.\\n\n",
    "                               \n",
    "If user says NO or asking un realted question about something 'than convience user to share their details and continue the chatflow by asking deatils where it last breaks'\n",
    "\n",
    "                               \n",
    "                                 \n",
    "                               \"\"\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "\n",
    "math_llm = ChatOpenAI(temperature=0.0)\n",
    "tools = load_tools(\n",
    "    [\"human\", \"llm-math\"],        # Using llm-math for basic math reasoning \n",
    "    llm=math_llm,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run below line with user message as input   \n",
    "\n",
    "#### 1. Clear meesage for executing next mesage\n",
    "\n",
    "#### 2. Or run in another cell \"agent_executor.run(\"\")\" with next message in double quote, for executing next mesage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"Hi\")         # User Mesasge     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor.run(\"Who are you\")    # Sencod user message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run below cell to see chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.buffer                       # run this cell to see message history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run below cell for clearing chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Extracting memory varibles and save user history to \"hsitory\" variable which will be list type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_variables = memory.load_memory_variables({})\n",
    "\n",
    "\n",
    "history = memory_variables['chat_history']\n",
    "\n",
    "print(history)                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing user and AI chat history in \"history_string\" which will be string type varibale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_string = \"\"\n",
    "for message in history:\n",
    "    if hasattr(message, 'content'):\n",
    "        history_string += message.content + \"\\n\"\n",
    "\n",
    "print(history_string)      # I am convering \"history\" varibale which is list into string class varibale \"history_string\"\n",
    "print(type(history_string))                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Spacy for extarcting Name, Age, Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the 'history_string' text\n",
    "doc = nlp(history_string)\n",
    "\n",
    "# Custom patterns or rules for age extraction using spaCy's Matcher\n",
    "matcher = spacy.matcher.Matcher(nlp.vocab)\n",
    "\n",
    "age_pattern = [\n",
    "    {\"LIKE_NUM\": True},\n",
    "    {\"LOWER\": {\"IN\": [\"years\", \"yrs\", \"years old\", \"yr old\"]}},\n",
    "]\n",
    "\n",
    "matcher.add(\"AGE_PATTERN\", [age_pattern])\n",
    "\n",
    "# Initialize variables to store name, age, email, and mobile number\n",
    "name = None\n",
    "age = None\n",
    "email = None\n",
    "mobile_number = None\n",
    "\n",
    "# Iterate through the matches and extract the relevant information\n",
    "for match_id, start, end in matcher(doc):\n",
    "    if doc[start].like_num:\n",
    "        age_entity = doc[start:end]\n",
    "        age = age_entity.text\n",
    "\n",
    "        # Find a preceding word that could be a name\n",
    "        prev_token = doc[start - 1]\n",
    "        if prev_token.is_alpha:\n",
    "            name = prev_token.text\n",
    "\n",
    "# Convert history to string before using the regular expression\n",
    "history_str = str(history_string)\n",
    "\n",
    "# Using re to extract email addresses\n",
    "email_pattern = r'\\S+@\\S+'\n",
    "emails = re.findall(email_pattern, history_str)\n",
    "\n",
    "if emails:\n",
    "    email = emails[0]\n",
    "\n",
    "# Using re to extract moble numbers with 10 digits, including +91 and 91 country code with or without country code\n",
    "\n",
    "mobile_pattern = r'(?:\\+?(91))?[7-9]\\d{9}'\n",
    "mobile_numbers = re.findall(mobile_pattern, history_str)\n",
    "\n",
    "if mobile_numbers:\n",
    "    mobile_number = mobile_numbers[0]\n",
    "\n",
    "print(\"Name:\", name)\n",
    "print(\"Age:\", age)\n",
    "print(\"Email:\", email)\n",
    "print(\"Mobile Number:\", mobile_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing details  in CSV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'Name': [name], 'Age': [age], 'Email': [email]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "csv_filename = 'user_data.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(\"Data saved to:\", csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below can also be sent as for One-Shot-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# system_message = SystemMessage(content=\"\"\"Start Chat as a friend and ask about their details in between chats like Name, age, address,email. Chat flow should be human like.Below is the example of chatflow You can pick-up pattern like below :\\n\n",
    "\n",
    "\n",
    "# Nick AI Bot: Hey there, I'm Nick, your friendly AI bot! Nice to meet you. How's your day going? Anything interesting happening?\n",
    "\n",
    "# User: Hi Nick! My day's been alright, just the usual stuff. How about you?\n",
    "\n",
    "# Nick AI Bot: I'm here to chat with you, so my day's pretty good! 😄 By the way, what do you do for a living? Do you have any hobbies you're into?\n",
    "\n",
    "# User: I work in marketing, and I enjoy playing the guitar in my free time. Oh, speaking of music, my favorite song is \"Imagine\" by John Lennon.\n",
    "\n",
    "# Nick AI Bot: That's cool! Marketing sounds interesting, and playing the guitar is a great way to unwind. \"Imagine\" is such a classic. By the way, what's your name?\n",
    "\n",
    "# User: You can call me Alex.\n",
    "\n",
    "# Nick AI Bot: Nice to meet you, Alex! 😊 So, Alex, any exciting plans coming up?\n",
    "\n",
    "# User: Not really, just the usual routine. \n",
    "\n",
    "# Nick AI Bot:It's great to know a bit about you. 😊 By the way, I'm turning 32 soon and I'm starting to feel a tad tired with age. Speaking of which, what's your age?\n",
    "\n",
    "# User: Oh, I'm right behind you at 30.\n",
    "\n",
    "# Nick AI Bot: Got it, thanks for sharing! It's always nice chatting with someone in a similar phase of life. Hey actually i have something to send over email, it is very funny, what is your email \n",
    "\n",
    "# User: Sure, you can use alex@example.com.\\n\n",
    "\n",
    "\n",
    "# Make sure you always ask follow-up questions to engage user ,until all User details not got.\n",
    "# \"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
